{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    input_paths =  ['2023-wimbledon-1313-player1.csv',\n",
    "                    '2023-wimbledon-1407-player1.csv',\n",
    "                    '2023-wimbledon-1504-player1.csv',\n",
    "                    ]\n",
    "    match_id = []\n",
    "    timestep = 10\n",
    "    batch_size = 64\n",
    "    feature_size = 12#16\n",
    "    hidden_size = 10 # TODO: can change\n",
    "    output_size = 4\n",
    "    predict_len = 5\n",
    "    num_layers = 2 # TODO: can change\n",
    "    epochs = 10 # TODO: can change\n",
    "    best_loss = 100\n",
    "    learning_rate = 0.005 # TODO: can change\n",
    "    model_name = 'GRU_for_tennis_momentum_swing_for_andrey_rublev'\n",
    "    save_path = './trained_models/{}.pth'.format(model_name)\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def delete_columns(input_file, output_file, columns_to_delete):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            # Exclude columns to delete (using 0-based index)\n",
    "            filtered_row = [value for idx, value in enumerate(row) if idx not in columns_to_delete]\n",
    "            writer.writerow(filtered_row)\n",
    "\n",
    "# Example usage:\n",
    "input_csv_file = config.input_paths[0]\n",
    "output_csv_file = 'your_output_file.csv'\n",
    "columns_to_delete = [10, 11, 14, 15]  # Columns are 0-based, so 11 becomes 10, 12 becomes 11, and so on.\n",
    "for input_path in config.input_paths:\n",
    "    delete_columns('./data_for_training/data/'+input_path, './data_for_training/data1/'+input_path, columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_data(dataX, dataY, flag, timestep, feature_size, output_size, pred_len):\n",
    "    myDataX = []\n",
    "    myDataY = []\n",
    "    for i in range(0, len(dataX) - timestep):\n",
    "        target_row = dataY[i + timestep - 1].reshape(-1, output_size)\n",
    "        res = []\n",
    "        for j in range(pred_len):\n",
    "            for k in range(output_size):\n",
    "                if target_row[j][k] == 1:\n",
    "                    if flag:\n",
    "                        res.append(2 - k if k % 2 == 0 else 4 - k)\n",
    "                    else:\n",
    "                        res.append(k)\n",
    "                    break\n",
    "        if len(res) != pred_len:\n",
    "            break\n",
    "        myDataX.append(dataX[i: i + timestep])\n",
    "        myDataY.append(res)\n",
    "    myDataX = np.array(myDataX)\n",
    "    myDataY = np.array(myDataY)\n",
    "\n",
    "    train_size = int(np.round(0.8 * myDataX.shape[0]))\n",
    "    trainX = myDataX[:train_size, :].reshape(-1, timestep, feature_size)\n",
    "    testX = myDataX[train_size:, :].reshape(-1, timestep, feature_size)\n",
    "    trainY = myDataY[:train_size, :].reshape(-1, pred_len)\n",
    "    testY = myDataY[train_size:, :].reshape(-1, pred_len)\n",
    "    return (trainX, trainY, testX, testY)\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "dfy = pd.read_csv('./data_for_training/momentum_condition.csv')\n",
    "dataY = np.array(dfy)\n",
    "# match_id: (start position, end position, 0 if player == player1 else)\n",
    "# match_id = [(0, 300, 0), (3788, 4013, 0), (5707, 5896, 0), (6589, 6748, 0), (6950, 7284, 0)] # for carlos_alcaraz\n",
    "# match_id = [(1972, 2185, 0), (4695, 4910, 0), (6179, 6372, 0), (6748, 6950, 0)] # for jannik sinner\n",
    "match_id = [(2948, 3238, 0), (5105, 5436, 0), (6372, 6589, 0)] # for andrey rublev\n",
    "match_no = 0\n",
    "\n",
    "for input_path in config.input_paths:\n",
    "    input_path = './data_for_training/data1/' + input_path\n",
    "    dfx = pd.read_csv(input_path)\n",
    "    dataX = np.array(dfx)\n",
    "    l, r, flag = match_id[match_no]\n",
    "    match_no += 1\n",
    "    a, b, c, d = fetch_data(dataX, dataY[l: r], flag, config.timestep, config.feature_size, config.output_size, config.predict_len)\n",
    "    \n",
    "    for x in a:\n",
    "        trainX.append(x)\n",
    "    for y in b:\n",
    "        trainY.append(y)\n",
    "    for x in c:\n",
    "        testX.append(x)\n",
    "    for y in d:\n",
    "        testY.append(y)\n",
    "trainX = np.array(trainX).reshape(-1, config.timestep, config.feature_size)\n",
    "testX = np.array(testX).reshape(-1, config.timestep, config.feature_size)\n",
    "trainY = np.array(trainY).reshape(-1, config.predict_len)\n",
    "testY = np.array(testY).reshape(-1, config.predict_len)\n",
    "\n",
    "x_train_tensor = torch.from_numpy(trainX).to(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(trainY).to(torch.long)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(testX).to(torch.float32)\n",
    "y_test_tensor = torch.from_numpy(testY).to(torch.long)\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, config.batch_size, False)\n",
    "test_loader = DataLoader(test_data, config.batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "class GRURNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, output_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(self.hidden_size, output_size)\n",
    "        self.fc4 = nn.Linear(self.hidden_size, output_size)\n",
    "        self.fc5 = nn.Linear(self.hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    " \n",
    "    def forward(self, input_seq):\n",
    "        batch_size = input_seq.shape[0]\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        output, _ = self.gru(input_seq,h_0)\n",
    "        pred1 = self.fc1(output)\n",
    "        pred2 = self.fc2(output)\n",
    "        pred3 = self.fc3(output)\n",
    "        pred4 = self.fc4(output)\n",
    "        pred5 = self.fc5(output)\n",
    "        pred1, pred2, pred3, pred4, pred5 = pred1[:, -1, :], pred2[:, -1, :], pred3[:, -1, :], pred4[:, -1, :], pred5[:, -1, :]\n",
    "        pred1, pred2, pred3, pred4, pred5 = self.softmax(pred1), self.softmax(pred2), self.softmax(pred3), self.softmax(pred4), self.softmax(pred5)\n",
    "        pred = torch.stack([pred1, pred2, pred3, pred4, pred5], dim=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GRURNN(config.feature_size, config.hidden_size, config.num_layers, config.output_size)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 197.60it/s]\n",
      "train epoch[2/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 210.54it/s]\n",
      "train epoch[3/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 170.18it/s]\n",
      "train epoch[4/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 254.26it/s]\n",
      "train epoch[5/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 220.24it/s]\n",
      "train epoch[6/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 204.39it/s]\n",
      "train epoch[7/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 159.49it/s]\n",
      "train epoch[8/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 227.41it/s]\n",
      "train epoch[9/10] loss: 6.855: 100%|███████████████████████████████████████████████████| 10/10 [00:00<00:00, 276.98it/s]\n",
      "train epoch[10/10] loss: 6.855: 100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 273.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for data in train_bar:\n",
    "        x_train, y_train = data\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(x_train)\n",
    "\n",
    "        loss1 = loss_function(y_train_pred[:, 0, :], y_train[:, 0])\n",
    "        loss2 = loss_function(y_train_pred[:, 1, :], y_train[:, 1])\n",
    "        loss3 = loss_function(y_train_pred[:, 2, :], y_train[:, 2])\n",
    "        loss4 = loss_function(y_train_pred[:, 3, :], y_train[:, 3])\n",
    "        loss5 = loss_function(y_train_pred[:, 4, :], y_train[:, 4])\n",
    "        # loss = max(loss1, loss2, loss3, loss4, loss5)\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "        # loss = 5 * loss1 + 2 * loss2 + loss3 + loss4 + loss5\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(\"loss =\", loss)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = 'train epoch[{}/{}] loss: {:.3f}'.format(epoch + 1, config.epochs, loss)\n",
    "    \n",
    "    # model.eval()\n",
    "    # test_loss = 0\n",
    "    # with torch.no_grad():\n",
    "    #     test_bar = tqdm(test_loader)\n",
    "    #     for data in test_bar:\n",
    "    #         x_test, y_test = data\n",
    "    #         y_test_pred = model(x_test)\n",
    "    #         loss1 = loss_function(y_test_pred[:, 0, :], y_test[:, 0])\n",
    "    #         loss2 = loss_function(y_test_pred[:, 1, :], y_test[:, 1])\n",
    "    #         loss3 = loss_function(y_test_pred[:, 2, :], y_test[:, 2])\n",
    "    #         loss4 = loss_function(y_test_pred[:, 3, :], y_test[:, 3])\n",
    "    #         loss5 = loss_function(y_test_pred[:, 4, :], y_test[:, 4])\n",
    "    #         # test_loss = max(loss1, loss2, loss3, loss4, loss5)\n",
    "    #         test_loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "    #         # test_loss = 5 * loss1 + 3 * loss2 + loss3 + loss4 + loss5\n",
    "    \n",
    "    # if test_loss < config.best_loss:\n",
    "    #     config.best_loss = test_loss\n",
    "    #     torch.save(model.state_dict(), config.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 96.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set predict rate for step 1 is: 0.422047\n",
      "train set predict rate for step 2 is: 0.390551\n",
      "train set predict rate for step 3 is: 0.384252\n",
      "train set predict rate for step 4 is: 0.387402\n",
      "train set predict rate for step 5 is: 0.376378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 98.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set predict rate for step 1 is: 0.436709\n",
      "test set predict rate for step 2 is: 0.392405\n",
      "test set predict rate for step 3 is: 0.386076\n",
      "test set predict rate for step 4 is: 0.449367\n",
      "test set predict rate for step 5 is: 0.398734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GRURNN(config.feature_size, config.hidden_size, config.num_layers, config.output_size)\n",
    "model.load_state_dict(torch.load(config.save_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_bar = tqdm(train_loader)\n",
    "\n",
    "    predict_rate = [0 for _ in range(config.predict_len)]\n",
    "    tot = [0 for _ in range(config.predict_len)]\n",
    "    for data in train_bar:\n",
    "        x_train, y_train = data\n",
    "        y_train_pred = model(x_train)\n",
    "        for i in range(config.predict_len):\n",
    "            tot[i] += x_train.shape[0]\n",
    "        for i in range(x_train.shape[0]):\n",
    "            for j in range(config.predict_len):\n",
    "                pred = 0\n",
    "                for k in range(config.output_size):\n",
    "                    if y_train_pred[i][j][k].item() > y_train_pred[i][j][pred].item():\n",
    "                        pred = k\n",
    "                predict_rate[j] += (1 if pred == y_train[i][j] else 0)\n",
    "    for i in range(config.predict_len):\n",
    "        print('train set predict rate for step {:d} is: {:f}'.format(i + 1, predict_rate[i] / tot[i]))\n",
    "    test_bar = tqdm(test_loader)\n",
    "\n",
    "    predict_rate = [0 for _ in range(config.predict_len)]\n",
    "    tot = [0 for _ in range(config.predict_len)]\n",
    "    for data in test_bar:\n",
    "        x_test, y_test = data\n",
    "        y_test_pred = model(x_test)\n",
    "        for i in range(config.predict_len):\n",
    "            tot[i] += x_test.shape[0]\n",
    "        for i in range(x_test.shape[0]):\n",
    "            for j in range(config.predict_len):\n",
    "                pred = 0\n",
    "                for k in range(config.output_size):\n",
    "                    if y_test_pred[i][j][k].item() > y_test_pred[i][j][pred].item():\n",
    "                        pred = k\n",
    "                predict_rate[j] += (1 if pred == y_test[i][j] else 0)\n",
    "    for i in range(config.predict_len):\n",
    "        print('test set predict rate for step {:d} is: {:f}'.format(i + 1, predict_rate[i] / tot[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), config.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_prediction(model, output_file):\n",
    "    model.eval()\n",
    "    \n",
    "    lst = []\n",
    "    column = ['is_train_set', 'pred_y1', 'pred_y2', 'pred_y3', 'pred_y4', 'pred_y5', 'target_y1', 'target_y2', 'target_y3', 'target_y4', 'target_y5']\n",
    "    with torch.no_grad():\n",
    "        train_bar = tqdm(train_loader)\n",
    "\n",
    "        predict_rate = [0 for _ in range(config.predict_len)]\n",
    "        tot = [0 for _ in range(config.predict_len)]\n",
    "        for data in train_bar:\n",
    "            x_train, y_train = data\n",
    "            y_train_pred = model(x_train)\n",
    "            for i in range(config.predict_len):\n",
    "                tot[i] += x_train.shape[0]\n",
    "            for i in range(x_train.shape[0]):\n",
    "                row = [1]\n",
    "                for j in range(config.predict_len):\n",
    "                    pred = 0\n",
    "                    for k in range(config.output_size):\n",
    "                        if y_train_pred[i][j][k].item() > y_train_pred[i][j][pred].item():\n",
    "                            pred = k\n",
    "                    predict_rate[j] += (1 if pred == y_train[i][j] else 0)\n",
    "                    row.append(pred)\n",
    "                for j in range(config.predict_len):\n",
    "                    row.append(y_train[i][j].item())\n",
    "                lst.append(row)\n",
    "        for i in range(config.predict_len):\n",
    "            print('train set predict rate for step {:d} is: {:f}'.format(i + 1, predict_rate[i] / tot[i]))\n",
    "        \n",
    "        test_bar = tqdm(test_loader)\n",
    "\n",
    "        predict_rate = [0 for _ in range(config.predict_len)]\n",
    "        tot = [0 for _ in range(config.predict_len)]\n",
    "        for data in test_bar:\n",
    "            x_test, y_test = data\n",
    "            y_test_pred = model(x_test)\n",
    "            for i in range(config.predict_len):\n",
    "                tot[i] += x_test.shape[0]\n",
    "            for i in range(x_test.shape[0]):\n",
    "                row = [0]\n",
    "                for j in range(config.predict_len):\n",
    "                    pred = 0\n",
    "                    for k in range(config.output_size):\n",
    "                        if y_test_pred[i][j][k].item() > y_test_pred[i][j][pred].item():\n",
    "                            pred = k\n",
    "                    predict_rate[j] += (1 if pred == y_test[i][j] else 0)\n",
    "                    row.append(pred)\n",
    "                for j in range(config.predict_len):\n",
    "                    row.append(y_test[i][j].item())\n",
    "                lst.append(row)\n",
    "        for i in range(config.predict_len):\n",
    "            print('test set predict rate for step {:d} is: {:f}'.format(i + 1, predict_rate[i] / tot[i]))\n",
    "    df = pd.DataFrame(lst, columns = column)\n",
    "    df.to_csv(output_file)\n",
    "\n",
    "model_alcaraz = GRURNN(config.feature_size, config.hidden_size, config.num_layers, config.output_size)\n",
    "model_sinner = GRURNN(config.feature_size, config.hidden_size, config.num_layers, config.output_size)\n",
    "model_rublev = GRURNN(config.feature_size, config.hidden_size, config.num_layers, config.output_size)\n",
    "\n",
    "model_alcaraz.load_state_dict(torch.load('./trained_models/GRU_for_tennis_momentum_swing_for_carlos_alcaraz.pth'))\n",
    "model_sinner.load_state_dict(torch.load('./trained_models/GRU_for_tennis_momentum_swing_for_jannik_sinner.pth'))\n",
    "model_rublev.load_state_dict(torch.load('./trained_models/GRU_for_tennis_momentum_swing_for_andrey_rublev.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------alcaraz------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 89.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set predict rate for step 1 is: 0.439779\n",
      "train set predict rate for step 2 is: 0.398895\n",
      "train set predict rate for step 3 is: 0.401105\n",
      "train set predict rate for step 4 is: 0.425414\n",
      "train set predict rate for step 5 is: 0.416575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 80.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set predict rate for step 1 is: 0.405286\n",
      "test set predict rate for step 2 is: 0.383260\n",
      "test set predict rate for step 3 is: 0.356828\n",
      "test set predict rate for step 4 is: 0.352423\n",
      "test set predict rate for step 5 is: 0.352423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------alcaraz------------')\n",
    "compute_prediction(model_alcaraz, './pred_res/model_alcaraz.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------sinner-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 93.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set predict rate for step 1 is: 0.522951\n",
      "train set predict rate for step 2 is: 0.537705\n",
      "train set predict rate for step 3 is: 0.521311\n",
      "train set predict rate for step 4 is: 0.498361\n",
      "train set predict rate for step 5 is: 0.483607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set predict rate for step 1 is: 0.424837\n",
      "test set predict rate for step 2 is: 0.405229\n",
      "test set predict rate for step 3 is: 0.379085\n",
      "test set predict rate for step 4 is: 0.372549\n",
      "test set predict rate for step 5 is: 0.339869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------sinner-------------')\n",
    "compute_prediction(model_sinner, './pred_res/model_sinner.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------rublev-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 81.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set predict rate for step 1 is: 0.422047\n",
      "train set predict rate for step 2 is: 0.390551\n",
      "train set predict rate for step 3 is: 0.384252\n",
      "train set predict rate for step 4 is: 0.387402\n",
      "train set predict rate for step 5 is: 0.376378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 106.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set predict rate for step 1 is: 0.436709\n",
      "test set predict rate for step 2 is: 0.392405\n",
      "test set predict rate for step 3 is: 0.386076\n",
      "test set predict rate for step 4 is: 0.449367\n",
      "test set predict rate for step 5 is: 0.398734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------rublev-------------')\n",
    "compute_prediction(model_rublev, './pred_res/model_rublev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPredictRate(model, test_loader):\n",
    "    model.eval()\n",
    "    predict_rate = [0 for _ in range(config.predict_len)]\n",
    "    tot = [0 for _ in range(config.predict_len)]\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_bar = tqdm(test_loader)\n",
    "\n",
    "        for data in test_bar:\n",
    "            x_test, y_test = data\n",
    "            y_test_pred = model(x_test)\n",
    "            for i in range(config.predict_len):\n",
    "                tot[i] += x_test.shape[0]\n",
    "            for i in range(x_test.shape[0]):\n",
    "                for j in range(config.predict_len):\n",
    "                    pred = 0\n",
    "                    for k in range(config.output_size):\n",
    "                        if y_test_pred[i][j][k].item() > y_test_pred[i][j][pred].item():\n",
    "                            pred = k\n",
    "                    predict_rate[j] += (1 if pred == y_test[i][j] else 0)\n",
    "    return np.array([predict_rate[i] / tot[i] for i in range(config.predict_len)])\n",
    "\n",
    "def calcFeatureImportance(model):\n",
    "    accuracy = calcPredictRate(model, test_loader)\n",
    "    importance = np.zeros(config.feature_size)\n",
    "    for i in range(config.feature_size):\n",
    "        ntestX = testX.copy()\n",
    "        nfeature = ntestX[:, :, i].copy().reshape(-1)\n",
    "        np.random.shuffle(nfeature)\n",
    "        nfeature = nfeature.reshape(-1, config.timestep)\n",
    "        for j in range(ntestX.shape[0]):\n",
    "            for k in range(ntestX.shape[1]):\n",
    "                ntestX[j][k][i] = nfeature[j][k]\n",
    "        nx_test_tensor = torch.from_numpy(ntestX).to(torch.float32)\n",
    "        ntest_data = TensorDataset(nx_test_tensor, y_test_tensor)\n",
    "        ntest_loader = DataLoader(ntest_data, config.batch_size, False)\n",
    "        naccuracy = calcPredictRate(model, ntest_loader)\n",
    "        importance[i] = sum([(accuracy[j] - naccuracy[j]) * (accuracy[j] - naccuracy[j]) for j in range(config.predict_len)])\n",
    "\n",
    "    tot = np.sum(importance)\n",
    "    for i in range(importance.shape[0]):\n",
    "        importance[i] = importance[i] / tot\n",
    "    \n",
    "    return importance\n",
    "\n",
    "column_name = ['model_name'] + ['f' + str(i + 1) for i in range(config.feature_size)]\n",
    "z = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 103.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 99.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 99.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 118.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 97.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 97.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 100.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 99.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 114.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 106.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 113.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 90.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 89.10it/s]\n"
     ]
    }
   ],
   "source": [
    "z.append(['alcaraz'] + calcFeatureImportance(model_alcaraz).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 116.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 108.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 105.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 101.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 111.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 139.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 101.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 121.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 86.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 116.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 103.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 113.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 96.11it/s]\n"
     ]
    }
   ],
   "source": [
    "z.append(['sinner'] + calcFeatureImportance(model_sinner).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 118.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 109.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 103.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 94.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 105.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 101.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 121.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 110.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 115.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 108.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 101.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 101.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 105.49it/s]\n"
     ]
    }
   ],
   "source": [
    "z.append(['rublev'] + calcFeatureImportance(model_rublev).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alcaraz', 0.02459016393442617, 0.06557377049180332, 0.01844262295081967, 0.4856557377049182, 0.07172131147540987, 0.07991803278688532, 0.08196721311475412, 0.04303278688524589, 0.0819672131147542, 0.02049180327868845, 0.006147540983606608, 0.020491803278688343], ['sinner', 0.07922912205567448, 0.012847965738758054, 0.01605995717344752, 0.2944325481798716, 0.16059957173447548, 0.16809421841541752, 0.10064239828693802, 0.022483940042826528, 0.08565310492505356, 0.0032119914346894858, 0.020342612419700205, 0.03640256959314774], ['rublev', 0.05651672433679354, 0.0034602076124567453, 0.025374855824682872, 0.5351787773933102, 0.051903114186851285, 0.10957324106113032, 0.018454440599769282, 0.06459054209919253, 0.03114186851211069, 0.061130334486735806, 0.006920415224913491, 0.035755478662053065]]\n"
     ]
    }
   ],
   "source": [
    "print(z)\n",
    "importance = pd.DataFrame(data=z, columns=column_name)\n",
    "importance.to_csv('./trained_models/feature_importance_for_specific_players.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
